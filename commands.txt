micromamba create -y -n gvae-cuda python=3.11 pytorch=2.3.* pytorch-cuda=12.1 -c pytorch -c nvidia -c conda-forge
# ついでに PyG 関連
micromamba activate gvae-cuda
pip install torch_geometric torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-2.3.0+cu121.html

curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj -C /work/01/jh210022o/q25030


curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj -C $HOME 


python - <<'PY'
import torch
print("GPU available:", torch.cuda.is_available())
print("Device:", torch.cuda.get_device_name(0))
PY


pjsub --interact -L rscgrp=share-interactive -g jh210022a